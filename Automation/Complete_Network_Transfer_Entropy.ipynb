{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hegdenischay/NEURONNet/blob/main/Automation/Complete_Network_Transfer_Entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBtbl9iM-hha"
      },
      "outputs": [],
      "source": [
        "size = 5\n",
        "dimension = \"High\" #do I even need this lol\n",
        "epochs =  20\n",
        "A_plus = 0.01 \n",
        "A_minus = -0.0011\n",
        "lateralDelay = 5\n",
        "currentAmp = 0.1"
      ],
      "id": "HBtbl9iM-hha"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_9d7LtSWFA0"
      },
      "source": [
        "# Install Neuron"
      ],
      "id": "L_9d7LtSWFA0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHPcM6GtV5K_"
      },
      "outputs": [],
      "source": [
        "pip install pandas neuron copent multiprocess"
      ],
      "id": "CHPcM6GtV5K_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1452ffae"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "totalstart = time.time()\n",
        "import os\n",
        "if os.getcwd() != \"/content\":\n",
        "    # we are not in google colab, assume hebbian library is in current dir\n",
        "    from hebb import ORN, MCELL, GCELL\n",
        "else:\n",
        "    # download from git\n",
        "    import shutil, requests\n",
        "    url = 'https://cloud.operationtulip.com/s/t8nbn8Y582w94P3/download/git.zip'\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open('git.zip', 'wb') as out_file:\n",
        "        shutil.copyfileobj(response.raw, out_file)\n",
        "    del response\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('git.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('')\n"
      ],
      "id": "1452ffae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63491b2a"
      },
      "outputs": [],
      "source": [
        "!nrnivmodl &>/dev/null"
      ],
      "id": "63491b2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYQ3O2_rte6s"
      },
      "outputs": [],
      "source": [
        "from neuron import h #.h is a HOC object instance & gui from neuron can also be imported \n",
        "from math import pi                  \n",
        "from neuron.units import ms,mV\n",
        "from hebb_test import ORN, MCELL, GCELL\n",
        "h.load_file('stdrun.hoc')                #Allows us to do a high level simulation\n",
        "pc = h.ParallelContext()\n",
        "import random  \n",
        "import matplotlib.pyplot as plt1\n",
        "\n",
        "from bokeh.io import output_notebook\n",
        "import bokeh.plotting as plt2\n",
        "output_notebook()\n",
        "\n",
        "import seaborn as sns"
      ],
      "id": "EYQ3O2_rte6s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o2Z2RO4_o5B"
      },
      "outputs": [],
      "source": [
        "def stairstep(lo: float, hi: float, duration: int, max_duration: int = 200, noise: list = []) -> list:\n",
        "    # duration and max_duration are in ms\n",
        "    ans = [lo if i < duration else hi for i in range(0,max_duration)]\n",
        "    if len(noise) == 0:\n",
        "        return ans\n",
        "    else:\n",
        "        assert len(ans) == len(noise)\n",
        "        return [ans[i]+noise[i] for i in range(len(ans))]\n",
        "    # return [0+0.8*(i/duration) if i < duration else 0 for i in range(0,max_duration)]\n",
        "    # visualize input "
      ],
      "id": "9o2Z2RO4_o5B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5odvQsJ7wzh_"
      },
      "outputs": [],
      "source": [
        "def netConMaker(source, dest, weights, delay, threshold, place='axon', type='exc'):\n",
        "    # print(source, dest)\n",
        "    if place == 'axon':\n",
        "        if type == 'exc':\n",
        "            netcon = h.NetCon(source.axon(0.5)._ref_v, dest.dendexcisyn, sec=source.axon)\n",
        "        elif type == 'inh':\n",
        "            netcon = h.NetCon(source.axon(0.5)._ref_v, dest.dendinhisyn, sec=source.axon)\n",
        "    elif place == 'soma':\n",
        "        if type == 'exc':\n",
        "            netcon = h.NetCon(source.soma(0.5)._ref_v, dest.dendexcisyn, sec=source.soma)\n",
        "        elif type == 'inh':\n",
        "            netcon = h.NetCon(source.soma(0.5)._ref_v, dest.dendinhisyn, sec=source.soma)\n",
        "    netcon.weight[0] = weights\n",
        "    netcon.delay = delay\n",
        "    netcon.threshold = threshold\n",
        "    return netcon"
      ],
      "id": "5odvQsJ7wzh_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyVJT9eYTbt1"
      },
      "outputs": [],
      "source": [
        "def latConMaker(source, dest, weights, delay, threshold, type='exc'):\n",
        "    if type == 'exc':\n",
        "        netcon = h.NetCon(source.dend(0.5)._ref_v, dest.dendexcisyn, sec=source.dend)\n",
        "    else:\n",
        "        netcon = h.NetCon(source.dend(0.5)._ref_v, dest.dendinhisyn, sec=source.dend)\n",
        "    netcon.weight[0] = weights\n",
        "    netcon.delay = delay\n",
        "    netcon.threshold = threshold\n",
        "    return netcon"
      ],
      "id": "fyVJT9eYTbt1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2RZsImWw1pX"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "def plotCell(source, name, addendum=''):\n",
        "    recording_cell = source\n",
        "    cell_axon = h.Vector().record(recording_cell.axon(0.5)._ref_v)\n",
        "    cell_dend = h.Vector().record(recording_cell.dend(0.5)._ref_v)\n",
        "    t = h.Vector().record(h._ref_t)\n",
        "\n",
        "    h.finitialize(-70 * mV)\n",
        "    h.continuerun(300 * ms)\n",
        "\n",
        "    f = plt1.figure(figsize=(16,9))\n",
        "    ax = f.add_subplot(1,1,1)\n",
        "    ax.plot(t, list(cell_axon), label=name+' axon '+addendum)\n",
        "    ax.plot(t, list(cell_dend), label=name+' dendrite '+addendum)\n",
        "    ax.legend(loc=\"upper right\")\n",
        "    ax.set_xlabel('t (ms)')\n",
        "    ax.set_ylabel('v (mV)')\n",
        "    plt1.show()"
      ],
      "id": "G2RZsImWw1pX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRU2J5WKw3Cm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def generate_L_weight_delta(first, second):\n",
        "    A_plus = 0.01\n",
        "    A_minus = -0.011\n",
        "    tau_pre =20*ms\n",
        "    tau_post =20*ms\n",
        "    delta_t = [(second[iter] - first[iter]) for iter in range(min(len(first),len(second)))]\n",
        "    delta_w_list = [A_plus*math.exp(-delta_t[iter]/tau_post) if delta_t[iter] >=0 else A_minus*math.exp(delta_t[iter]/tau_pre) for iter in range(min(len(first),len(second)))]  \n",
        "    delta_w = sum(delta_w_list)\n",
        "    return delta_w"
      ],
      "id": "fRU2J5WKw3Cm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6OJ0E7jV4nG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "import time\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "id": "K6OJ0E7jV4nG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGDhgsQEYa2X"
      },
      "outputs": [],
      "source": [
        "class AON:\n",
        "    def __init__(self,M,weights,delay1=1,delay2=2,delay3=3,delay4=4):\n",
        "        wMM=weights[0]\n",
        "        wMG=weights[1]\n",
        "        wGM=weights[2]\n",
        "        wGG=weights[3]\n",
        "        \n",
        "        self.M = M #Set no.\n",
        "        self.th = -70\n",
        "        self.maindelay = 5\n",
        "\n",
        "        self.M1=MCELL(1,self.M)\n",
        "        self.M2=MCELL(2,self.M)\n",
        "        self.G1=GCELL(3,self.M)\n",
        "        self.G2=GCELL(4,self.M)\n",
        "        self.cells = [self.M1, self.M2, self.G1, self.G2]\n",
        "        \n",
        "        self.nc0 = netConMaker(self.M1, self.M2, wMM, delay1+self.maindelay, self.th, 'soma') #Connecting E1 to E2\n",
        "        self.nc1 = netConMaker(self.M2, self.M1, wMM, delay2+self.maindelay, self.th, 'soma') #Connecting E2 to E1\n",
        "        self.nc2 = netConMaker(self.M2, self.G1, wMG, delay2+self.maindelay, self.th, 'soma') #Connecting E2 to I1\n",
        "        self.nc3 = netConMaker(self.G1, self.M2, wGM, delay3+self.maindelay, self.th, 'soma', type='inh') #Connecting I1 to E2\n",
        "        self.nc4 = netConMaker(self.G1, self.G2, wGG, delay3+self.maindelay, self.th, 'soma', type='inh') #Connecting I1 to I2\n",
        "        self.nc5 = netConMaker(self.G2, self.G1, wGG, delay4+self.maindelay, self.th, 'soma', type='inh') #Connecting I2 to I1\n",
        "        self.nc6 = netConMaker(self.G2, self.M1, wGM, delay4+self.maindelay, self.th, 'soma', type='inh') #Connecting I2 to E1\n",
        "        self.nc7 = netConMaker(self.M1, self.G2, wMG, delay1+self.maindelay, self.th, 'soma') #Connecting E1 to I2\n",
        "        self.nc8 = netConMaker(self.M1, self.G1, wMG, delay1+self.maindelay, self.th, 'soma') #Connecting E1 to I1\n",
        "        self.nc9 = netConMaker(self.G1, self.M1, wGM, delay3+self.maindelay, self.th, 'soma', type='inh') #Connecting I1 to E1"
      ],
      "id": "IGDhgsQEYa2X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b8b7d01"
      },
      "outputs": [],
      "source": [
        "#Gives one 2 coupled neuron using freeman's topology in olfactory bulb\n",
        "class CONNECTING:\n",
        "\n",
        "    def __init__(self,M,weights,delay1=0,delay2=2,delay3=4,delay4=6):\n",
        "        wMM=weights[0]\n",
        "        wMG=weights[1]\n",
        "        wGM=weights[2]\n",
        "        wGG=weights[3]\n",
        "        \n",
        "        self.M = M #Set no.\n",
        "        self.th = -70\n",
        "        self.maindelay = 5\n",
        "        \n",
        "        #Making 2 neurons\n",
        "        self.orn = ORN(1,self.M)\n",
        "        self.P1=MCELL(2,self.M)\n",
        "        self.P2=MCELL(3,self.M)\n",
        "        self.cells = [self.orn, self.P1, self.P2]\n",
        "        \n",
        "        #Giving current pulse\n",
        "        self.stim = h.IClamp(self.orn.dend(0.5))  #P1.soma to P1.dend\n",
        "        # self.stimArr = [h.IClamp(self.orn.ciliumArr[i](0.5)) for i in range(len(self.orn.ciliumArr))]\n",
        "        self.stim.delay = 10\n",
        "        self.stim.dur = 100\n",
        "        self.stim.amp = currentAmp\n",
        "        \n",
        "        self.nc0 = netConMaker(self.orn, self.P1, wMM, self.maindelay+delay2, self.th, 'soma') #Connecting ORN to P1\n",
        "        self.nc1 = netConMaker(self.P1, self.P2, wMM, self.maindelay+delay3, self.th, 'soma') #Connecting P1 to P2\n",
        "        self.nc2 = netConMaker(self.P2, self.P1, wMM, self.maindelay+delay3, self.th, 'soma') #Connecting P2 to P1\n",
        "    \n",
        "        # 4-coupled\n",
        "\n",
        "        self.M1=MCELL(1,self.M)\n",
        "        self.M2=MCELL(2,self.M)\n",
        "        self.G1=GCELL(3,self.M)\n",
        "        self.G2=GCELL(4,self.M)\n",
        "        self.cells.extend([self.M1, self.M2, self.G1, self.G2])\n",
        "\n",
        "        self.nc14 = netConMaker(self.orn, self.M1, wMM, delay1+self.maindelay, self.th, 'soma')\n",
        "        self.nc3 = netConMaker(self.P1, self.M1, wMM, delay1+self.maindelay, self.th, 'soma')\n",
        "        self.nc4 = netConMaker(self.M1, self.M2, wMM, delay2+self.maindelay, self.th, 'soma') #Connecting M1 to M2\n",
        "        self.nc5 = netConMaker(self.M2, self.M1, wMM, delay2+self.maindelay, self.th, 'soma') #Connecting M2 to M1\n",
        "        self.nc6 = netConMaker(self.M2, self.G1, wMG, delay2+self.maindelay, self.th, 'soma') #Connecting M2 to G1\n",
        "        self.nc7 = netConMaker(self.G1, self.M2, wGM, delay2+self.maindelay, self.th, 'soma', type='inh') #Connecting G1 to M2\n",
        "        self.nc8 = netConMaker(self.G1, self.G2, wGG, delay3+self.maindelay, self.th, 'soma', type='inh') #Connecting G1 to G2\n",
        "        self.nc9 = netConMaker(self.G2, self.G1, wGG, delay3+self.maindelay, self.th, 'soma', type='inh') #Connecting G2 to G1\n",
        "        self.nc10 = netConMaker(self.G2, self.M1, wGM, delay4+self.maindelay, self.th, 'soma', type='inh') #Connecting G2 to M1\n",
        "        self.nc11 = netConMaker(self.M1, self.G2, wMG, delay4+self.maindelay, self.th, 'soma') #Connecting M1 to G2\n",
        "        self.nc12 = netConMaker(self.M1, self.G1, wMG, delay1+self.maindelay, self.th, 'soma') #Connecting M1 to G1\n",
        "        self.nc13 = netConMaker(self.G1, self.M1, wGM, delay1+self.maindelay, self.th, 'soma', type='inh') #Connecting G1 to M1"
      ],
      "id": "6b8b7d01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3d8b0fd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LATERAL:\n",
        "    \"\"\"Laterally coupling N-2 coupled neurons\n",
        "    \"\"\"\n",
        "    def __init__(self,N,weights,delay1=0,delay2=2,delay3=4,delay4=6):\n",
        "        wMML=weights[1]\n",
        "        wGGL=weights[5]\n",
        "        \n",
        "        self.N = N\n",
        "        self.th = -70\n",
        "        self.maindelay = lateralDelay\n",
        "        self.sets = [CONNECTING(i, weights) for i in range(N)]\n",
        "            \n",
        "        self.twoCupArr = []\n",
        "        for r in range(0,N-1):\n",
        "          #Connecting P1[0] to P1[1]\n",
        "          # make a list for easier access\n",
        "          netConList = []\n",
        "          netConList.append(latConMaker(self.sets[r].P1, self.sets[r+1].P1,wMML,self.maindelay+delay2,self.th)) #P1[0] to P1[1]\n",
        "          netConList.append(latConMaker(self.sets[r+1].P1, self.sets[r].P1, wMML, self.maindelay+delay2,self.th))\n",
        "\n",
        "          self.twoCupArr.append(netConList)\n",
        "        self.fourCupArr = []\n",
        "        for r in range(1,N-1):\n",
        "            for j in range(N-r):\n",
        "                netConList = []\n",
        "                netConList.append(latConMaker(self.sets[j].M1, self.sets[j+r].M1, wMML, self.maindelay+delay3, self.th)) #Connect M1[0] to M1[1]\n",
        "                netConList.append(latConMaker(self.sets[j+r].M1, self.sets[j].M1, wMML, self.maindelay+delay3, self.th)) #Connect M1[1] to M1[0]\n",
        "                netConList.append(latConMaker(self.sets[j].G1, self.sets[j+r].G1, wGGL, self.maindelay+delay2, self.th, 'inh')) #Connecting G1[0] to G1[1]\n",
        "                netConList.append(latConMaker(self.sets[j+r].G1, self.sets[j].G1, wGGL, self.maindelay+delay2, self.th, 'inh')) #Connecting G1[1] to G1[0]\n",
        "                self.fourCupArr.append(netConList)\n",
        "\n",
        "        # add AON and PC\n",
        "        self.AON = AON(5,weights)\n",
        "        self.PC = AON(6,weights)\n",
        "        self.DPC = GCELL(7,self.N)\n",
        "        # add noise to AON's M1\n",
        "        self.stim = h.IClamp(self.AON.M1.dend(0.5))  #P1.soma to P1.dend\n",
        "        self.noise = np.random.normal(0, 0.1, 100)\n",
        "        self.input = h.Vector(self.noise)\n",
        "        self.tv = h.Vector([i for i in range(100)])\n",
        "        self.input.play(self.stim._ref_amp, self.tv, True)\n",
        "        self.otherNetCons = []\n",
        "        self.otherNetCons.append(netConMaker(self.sets[0].M1, self.AON.M1, wMML, self.maindelay+delay2, self.th, 'soma')) # 4-coupled M1 -> AON's E1\n",
        "        for i in self.sets:\n",
        "            for j in self.sets:\n",
        "                if i != j:\n",
        "                    self.otherNetCons.append(netConMaker(i.P1, j.P1, wMML, self.maindelay+delay2, self.th, 'soma')) # all-to-all in P1\n",
        "                    self.otherNetCons.append(netConMaker(i.M1, j.M1, wMML, self.maindelay+delay3, self.th, 'soma')) # all-to-all in M1\n",
        "                    self.otherNetCons.append(netConMaker(i.G1, j.G1, wGGL, self.maindelay+delay2, self.th, 'soma')) # all-to-all in M1\n",
        "\n",
        "        for i in self.sets:\n",
        "            self.otherNetCons.append(netConMaker(self.AON.M1, i.P2, wMML, self.maindelay+delay2, self.th, 'soma')) # AON E1 -> 2-coupled P2\n",
        "        if dimension == \"High\":\n",
        "            self.otherNetCons.append(netConMaker(self.PC.M1, self.AON.G1, wMML, self.maindelay+delay3+10, self.th, 'soma')) # PC's A1 to AON's I1\n",
        "        self.otherNetCons.append(netConMaker(self.sets[0].M1, self.PC.M1, wMML, self.maindelay+delay2, self.th, 'soma')) # M1 to A1\n",
        "        for i in self.sets:\n",
        "            self.otherNetCons.append(netConMaker(self.AON.M1, i.G1, wMML, self.maindelay+delay2, self.th, 'soma')) # AON's E1 -> 4-coupled G1\n",
        "        \n",
        "        self.otherNetCons.append(netConMaker(self.PC.G1, self.DPC, wMML/100000, self.maindelay+delay3, self.th, 'soma', 'inh')) # PC's B1 -> DPC\n",
        "        self.otherNetCons.append(netConMaker(self.DPC, self.PC.G1, wMML/100000, self.maindelay+delay3, self.th, 'soma')) # DPC -> PC's B1\n",
        "        if dimension == \"High\":\n",
        "            for i in self.sets:\n",
        "                self.otherNetCons.append(netConMaker(self.DPC, i.G1, wMML/100000, self.maindelay+delay3+10, self.th))# DPC to G1 \n",
        "        self.otherNetCons.append(netConMaker(self.sets[-1].G1, self.DPC, wMML, self.maindelay+4, self.th, 'soma'))\n",
        "        \n"
      ],
      "id": "e3d8b0fd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "665f6425"
      },
      "outputs": [],
      "source": [
        "#Give N value to get N no. of 2 coupled neurons laterally connected\n",
        "#given_input_from_user = int(input('Enter the number of 2 coupled sets required: '))\n",
        "import numpy as np\n",
        "# size = 5\n",
        "low, high = 1, 5\n",
        "weights = np.random.uniform(low, high, 2*size-1)\n",
        "# all_weights = np.random.uniform(low, high,2*given_input_from_user-1)\n",
        "# all_weights = [4.65058555, 2.92840154, 3.68134116, 1.30487304, 1.07771946, 3.15136447, 1.04247865, 2.29878494, 2.01195344]\n",
        "# all_weights = [0.95336892, 0.87793015, 0.71060386, 0.88298338, 0.84561174, 0.5006465, 0.60983793, 0.88890724, 0.85189888]\n",
        "L1=LATERAL(size,weights)"
      ],
      "id": "665f6425"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfmf2k-NDN29"
      },
      "outputs": [],
      "source": [
        "def learn():\n",
        "    import sys, time\n",
        "    tick = time.time()\n",
        "    weight_data = []\n",
        "\n",
        "    out = display(progress(0, epochs), display_id=True)\n",
        "\n",
        "    for l in range(epochs):\n",
        "        #print(\"iteration no is\",l)\n",
        "        out.update(progress(l, epochs))    \n",
        "        # print(\"\\nmutual learning\")\n",
        "        P1_axon_data = []\n",
        "        P1_dend_data = []\n",
        "        P2_axon_data = []\n",
        "        P2_dend_data = []\n",
        "        M1_axon_data = []\n",
        "        M1_dend_data = []\n",
        "        M2_axon_data = []\n",
        "        M2_dend_data = []\n",
        "        G1_axon_data = []\n",
        "        G1_dend_data = []\n",
        "        G2_axon_data = []\n",
        "        G2_dend_data = []\n",
        "        P1_spike_times = []\n",
        "        P2_spike_times = []\n",
        "        M1_spike_times = []\n",
        "        M2_spike_times = []\n",
        "        G1_spike_times = []\n",
        "        G2_spike_times = []\n",
        "\n",
        "        h.finitialize(-70* mV)\n",
        "        h.continuerun(300*ms)\n",
        "        t = h.Vector().record(h._ref_t)\n",
        "        \n",
        "        for i in range(len(L1.sets)):\n",
        "            P1_axon_data.append(list(h.Vector().record(L1.sets[i].P1.axon(0.5)._ref_v)))\n",
        "            P1_dend_data.append(list(h.Vector().record(L1.sets[i].P1.dend(0.5)._ref_v)))\n",
        "            P1_spike_times.append(list(L1.sets[i].P1.spike_times))\n",
        "            P2_axon_data.append(list(h.Vector().record(L1.sets[i].P2.axon(0.5)._ref_v)))\n",
        "            P2_spike_times.append(list(L1.sets[i].P2.spike_times))\n",
        "            P2_dend_data.append(list(h.Vector().record(L1.sets[i].P2.dend(0.5)._ref_v)))\n",
        "            M1_axon_data.append(list(h.Vector().record(L1.sets[i].M1.axon(0.5)._ref_v)))\n",
        "            M1_dend_data.append(list(h.Vector().record(L1.sets[i].M1.dend(0.5)._ref_v)))\n",
        "            M1_spike_times.append(list(L1.sets[i].M1.spike_times))\n",
        "            M2_axon_data.append(list(h.Vector().record(L1.sets[i].M2.axon(0.5)._ref_v)))\n",
        "            M2_dend_data.append(list(h.Vector().record(L1.sets[i].M2.dend(0.5)._ref_v)))\n",
        "            M2_spike_times.append(list(L1.sets[i].M2.spike_times))\n",
        "            G1_axon_data.append(list(h.Vector().record(L1.sets[i].G1.axon(0.5)._ref_v)))\n",
        "            G1_dend_data.append(list(h.Vector().record(L1.sets[i].G1.dend(0.5)._ref_v)))\n",
        "            G1_spike_times.append(list(L1.sets[i].G1.spike_times))\n",
        "            G2_axon_data.append(list(h.Vector().record(L1.sets[i].G2.axon(0.5)._ref_v)))\n",
        "            G2_dend_data.append(list(h.Vector().record(L1.sets[i].G2.dend(0.5)._ref_v)))\n",
        "            G2_spike_times.append(list(L1.sets[i].G2.spike_times))\n",
        "\n",
        "    \n",
        "        # h.finitialize(-70 * mV)\n",
        "\n",
        "        for i in range(len(L1.sets)):\n",
        "            # 2-coupled STDP-based learning\n",
        "            L1.sets[i].nc1.weight[0] += generate_L_weight_delta(P1_spike_times[i], P2_spike_times[i])\n",
        "            # logging\n",
        "            # print(\"P1_axon\", P1_spike_times[i], P2_spike_times[i])\n",
        "            L1.sets[i].nc2.weight[0] += generate_L_weight_delta(P2_spike_times[i], P1_spike_times[i])\n",
        "            L1.sets[i].nc3.weight[0] += generate_L_weight_delta(P1_spike_times[i], M1_spike_times[i])\n",
        "            # 4-coupled STDP-based learning\n",
        "            L1.sets[i].nc4.weight[0] += generate_L_weight_delta(M1_spike_times[i], M2_spike_times[i])\n",
        "            L1.sets[i].nc5.weight[0] += generate_L_weight_delta(M2_spike_times[i], M1_spike_times[i])\n",
        "            L1.sets[i].nc6.weight[0] += generate_L_weight_delta(M2_spike_times[i], G1_spike_times[i])\n",
        "            L1.sets[i].nc7.weight[0] += generate_L_weight_delta(G1_spike_times[i], M2_spike_times[i])\n",
        "            L1.sets[i].nc8.weight[0] += generate_L_weight_delta(G1_spike_times[i], G2_spike_times[i])\n",
        "            L1.sets[i].nc9.weight[0] += generate_L_weight_delta(G2_spike_times[i], G1_spike_times[i])\n",
        "            L1.sets[i].nc10.weight[0] += generate_L_weight_delta(G2_spike_times[i], M1_spike_times[i])\n",
        "            L1.sets[i].nc11.weight[0] += generate_L_weight_delta(M1_spike_times[i], G2_spike_times[i])\n",
        "            L1.sets[i].nc12.weight[0] += generate_L_weight_delta(M1_spike_times[i], G1_spike_times[i])\n",
        "            L1.sets[i].nc13.weight[0] += generate_L_weight_delta(G1_spike_times[i], M1_spike_times[i])\n",
        "            # L1.sets[i].DPC.weight[0] += generate_L_weight_delta(G1_spike_times[i], M1_spike_times[i])\n",
        "            \n",
        "        # do a proper logging function\n",
        "        weight_data.append(L1.sets[0].nc1.weight[0])\n",
        "\n",
        "\n",
        "        #Lateral Learning\n",
        "        for i in range(len(L1.sets)-1):\n",
        "            # 2-coupled part\n",
        "            L1.twoCupArr[i][0].weight[0] += generate_L_weight_delta(P1_spike_times[i], P1_spike_times[i+1])\n",
        "            L1.twoCupArr[i][1].weight[0] += generate_L_weight_delta(P1_spike_times[i+1], P1_spike_times[i])\n",
        "            # 4-coupled part\n",
        "            L1.fourCupArr[i][0].weight[0] += generate_L_weight_delta(M1_spike_times[i], M1_spike_times[i+1])\n",
        "            L1.fourCupArr[i][1].weight[0] += generate_L_weight_delta(M1_spike_times[i+1], M1_spike_times[i])\n",
        "            L1.fourCupArr[i][2].weight[0] += generate_L_weight_delta(G1_spike_times[i], G1_spike_times[i+1])\n",
        "            L1.fourCupArr[i][3].weight[0] += generate_L_weight_delta(G1_spike_times[i+1], G1_spike_times[i])\n",
        "        # plotCell(L1.sets[-1].M1, 'M1')\n",
        "\n",
        "\n",
        "    out.update(progress(epochs, epochs))    \n",
        "    tock = time.time()\n",
        "    print(\"The time it took to learn\", tock-tick, \"seconds\")"
      ],
      "id": "Xfmf2k-NDN29"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Entropy while changing weights"
      ],
      "metadata": {
        "id": "7gPU8JL9ikVq"
      },
      "id": "7gPU8JL9ikVq"
    },
    {
      "cell_type": "code",
      "source": [
        "from copent import transent\n",
        "# import the threading module\n",
        "from multiprocessing import Process\n",
        "\n",
        "M1Arr = []\n",
        "M2Arr = []\n",
        " \n",
        "def f(resList, arg1, arg2):\n",
        "    resList.append(transent(list(arg1)[::5], list(arg2)[::5],2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for M1weight in np.arange(0.1, 10, 0.5):\n",
        "        L1 = LATERAL(size,weights)\n",
        "        for i in range(len(L1.sets)):\n",
        "            L1.sets[0].nc4.weight[0] = M1weight\n",
        "        learn()\n",
        "        M1Voltage = h.Vector().record(L1.sets[0].M1.axon(0.5)._ref_v)\n",
        "        M2Voltage = h.Vector().record(L1.sets[0].M2.axon(0.5)._ref_v)\n",
        "        h.finitialize(-70*mV)\n",
        "        h.continuerun(300*ms)\n",
        "        p = Process(target=f, args=(M1Arr, M1Voltage, M2Voltage,))\n",
        "        p2 = Process(target=f, args=(M2Arr, M2Voltage, M1Voltage,))\n",
        "        p.start()\n",
        "        p2.start()\n",
        "        p.join()\n",
        "        p2.join()\n",
        "        print(\"Done\")"
      ],
      "metadata": {
        "id": "iokid8g4jQQY"
      },
      "id": "iokid8g4jQQY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(np.arange(0.1,2,0.1),M1Arr)\n",
        "plt.plot(np.arange(0.1,2,0.1),M2Arr)"
      ],
      "metadata": {
        "id": "TQYIwTyYkxfx"
      },
      "id": "TQYIwTyYkxfx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IReY5q2pbeAt"
      },
      "id": "IReY5q2pbeAt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L_9d7LtSWFA0",
        "MWYTz03xLsWS",
        "IqVU4uAHwxiJ",
        "90Kn6XE2V6nW",
        "VWHFMMFXWjhI",
        "N5NCjS3XWr6s",
        "8b2874e2",
        "8ba65a81",
        "4tGgp4nPXab1",
        "dpdAXofpXg5X",
        "4fsYjO7nXqIO",
        "RYcaSlQaX8NY"
      ],
      "name": "Latest: Complete Network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}